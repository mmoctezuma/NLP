{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mario Alberto Moctezuma Salazar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Complaints = pd.read_csv('Consumer_Complaints.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h1> <center> ML for product prediction </center> </h1>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Approach 1:* MultinomialNB applied to `Consumer complaint narrative` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Why this model?* We use this method to consider maximum likelihood using the bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we create a  `DataFrame` containing only `Consumer complaint narrative` different from `NaN`.\n",
    "### Here we take\n",
    "``\n",
    "X1 = Nar_complaints['Consumer complaint narrative']\n",
    "y1 = Nar_complaints.Product\n",
    "``\n",
    "### Then we make a pipeline where we vectorize the text, eliminate \"stop words\" in english, and apply the method MultinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nar_complaints = Complaints.dropna(subset=['Consumer complaint narrative'])\n",
    "Nar_complaints = Nar_complaints.reset_index(drop=True)\n",
    "\n",
    "X1 = Nar_complaints['Consumer complaint narrative']\n",
    "y1 = Nar_complaints.Product\n",
    "\n",
    "text_clf = Pipeline([('tfidf', TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000, stop_words='english')),\n",
    "                     ('clf', MultinomialNB(alpha=1.0e-10)),])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we create our own function to validate and calculate the accuracy for each fold, since there is not cross-validation technique for `str` data. In the second cell below we can see the accuracy score of each fold and the mean of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "\n",
    "\n",
    "def kfold(X, y, kf, pipe):\n",
    "    acc_list = []\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        pipe.fit(X[train_idx], y[train_idx])\n",
    "        predd = pipe.predict(X[test_idx])\n",
    "        acc = accuracy_score(y[test_idx], predd)\n",
    "        print(acc)\n",
    "    acc_list.append(acc)\n",
    "    return np.mean(acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874983653720413\n",
      "0.7918573732618456\n",
      "0.7915086526306613\n",
      "0.7918573732618456\n",
      "0.7884045335658239\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7884045335658239"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kfold(X1, y1, kf, text_clf) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that the accuracy scores above are not that different , which roughly means that any subset to test is good. Besides, based on the mean value of the accuaracy of the folds, we can predict the product from the text of the 'Consumer complaint narrative', with an 78.8% of accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Approach 2:* MultinomialNB applied to `Issue`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the column of `Consumer complaint narrative` has many `NaN`, we consider the `Issues` column and `MultinomialNB`:\n",
    "\n",
    "\n",
    "### Here we take\n",
    "``\n",
    "X2 = Complaints.Issue\n",
    "y2 = Complaints.Product\n",
    "``\n",
    "### Then we make a pipeline where we choose vectorize with `TfidfTransformer()` since the `Issue` column is quite standard in its values. Applying the method we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = Complaints.Issue\n",
    "y2 = Complaints.Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9844915001491202\n",
      "0.9851774530271399\n",
      "0.9842156277960036\n",
      "0.9849834848157234\n",
      "0.9846703300800036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9846703300800036"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf2 = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB(alpha=1.0e-10)),])\n",
    "\n",
    "kfold(X2, y2, kf, text_clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that the accuracy scores above are not that different among them, but *significantly* better than those of the first approach. The latter is possibly due to the \"standard\" values of the `Issue` column.\n",
    "\n",
    "### Here we predict the product with an 98.4% of accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
